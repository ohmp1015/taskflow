// âœ… FILE: /lib/chat-to-doc.ts

// Stream AI answer with real-time chunks and persist final answer to DB
// content - document content for context
// question - user's question
// docId - document ID for saving chat
// save - callback to save final answer
// onChunk - callback for streaming UI updates
import { api } from "@/convex/_generated/api";
import { useMutation, useQuery } from "convex/react";

export async function streamDocumentAnswer(
  content: string,
  question: string,
  docId: string,
  save: (answer: string) => void,
  onChunk: (text: string) => void
) {
  const res = await fetch("/api/chat-to-doc", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ content, question, docId, stream: true }),
  });

  if (!res.ok || !res.body) throw new Error("Failed to get stream from AI");

  const reader = res.body.getReader();
  const decoder = new TextDecoder("utf-8");

  let answer = "";
  let done = false;
  while (!done) {
    const { value, done: isDone } = await reader.read();
    done = isDone;
    const chunk = decoder.decode(value);
    answer += chunk;
    onChunk(chunk); // stream chunk to frontend
  }

  save(answer); // final full answer
}


// âœ… FILE: /app/api/chat-to-doc/route.ts

// Handles chat requests with OpenAI and saves chat to Convex DB
import { NextRequest } from "next/server";
import OpenAI from "openai";
import { api } from "@/convex/_generated/api";
import { ConvexHttpClient } from "convex/browser";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });
const convex = new ConvexHttpClient(process.env.NEXT_PUBLIC_CONVEX_URL!);

export async function POST(req: NextRequest) {
  const { content, question, docId, stream } = await req.json();

  const messages = [
    {
      role: "system",
      content: `You are a helpful assistant. Use the following document content to answer any questions:\n\n${content}`,
    },
    { role: "user", content: question },
  ];

  if (stream) {
    const encoder = new TextEncoder();
    let fullAnswer = "";

    const streamRes = new ReadableStream({
      async start(controller) {
        const completion = await openai.chat.completions.create({
          model: "gpt-4",
          stream: true,
          messages,
        });

        for await (const chunk of completion) {
          const text = chunk.choices[0]?.delta?.content || "";
          fullAnswer += text;
          controller.enqueue(encoder.encode(text));
        }

        // Save final full response to DB
        await convex.mutation(api.chats.saveChatMessage, {
          documentId: docId,
          question,
          answer: fullAnswer,
        });

        controller.close();
      },
    });

    return new Response(streamRes, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-cache",
      },
    });
  }

  const result = await openai.chat.completions.create({ model: "gpt-4", messages });
  const answer = result.choices[0].message.content?.trim() || "";

  // Save single-shot answer to DB
  await convex.mutation(api.chats.saveChatMessage, {
    documentId: docId,
    question,
    answer,
  });

  return new Response(JSON.stringify({ answer }), { headers: { "Content-Type": "application/json" } });
}


// âœ… FILE: /components/document/chat-to-doc.tsx

// Client component for displaying document-based AI chat
"use client";

import { useEffect, useState } from "react";
import { streamDocumentAnswer } from "@/lib/chat-to-doc";
import { Input } from "@/components/ui/input";
import { Button } from "@/components/ui/button";
import { useQuery } from "convex/react";
import { api } from "@/convex/_generated/api";

interface ChatToDocProps {
  content: string;
  documentId: string;
}

interface ChatMessage {
  role: "user" | "assistant";
  content: string;
}

export function ChatToDoc({ content, documentId }: ChatToDocProps) {
  const [question, setQuestion] = useState("");
  const [loading, setLoading] = useState(false);
  const [messages, setMessages] = useState<ChatMessage[]>([]);

  // Load chat history from Convex
  const savedChats = useQuery(api.chats.getChatMessages, { documentId });

  // Set state when chat loads
  useEffect(() => {
    if (savedChats) {
      const loaded = savedChats.flatMap((chat) => [
        { role: "user" as const, content: chat.question },
        { role: "assistant" as const, content: chat.answer },
      ]);
      setMessages(loaded);
    }
  }, [savedChats]);

  // Handle asking question + streaming answer
  const handleAsk = async () => {
    if (!question.trim()) return;
    const newMessages = [...messages, { role: "user", content: question }, { role: "assistant", content: "" }];
    setMessages(newMessages);
    setQuestion("");
    setLoading(true);

    try {
      await streamDocumentAnswer(content, question, documentId, () => {}, (chunk) => {
        setMessages((prev) => {
          const updated = [...prev];
          const last = updated[updated.length - 1];
          if (last.role === "assistant") last.content += chunk;
          return [...updated];
        });
      });
    } catch (err) {
      console.error(err);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="mt-8 p-4 border rounded-xl space-y-4">
      <h3 className="text-lg font-semibold">ðŸ¤– Ask AI about this document</h3>

      {/* Render all chat messages */}
      <div className="space-y-2 max-h-64 overflow-y-auto">
        {messages.map((msg, idx) => (
          <div
            key={idx}
            className={`rounded-lg px-3 py-2 max-w-xl text-sm whitespace-pre-wrap ${
              msg.role === "user"
                ? "bg-blue-100 self-end text-right ml-auto"
                : "bg-gray-100 text-left mr-auto"
            }`}
          >
            <strong className="block text-xs text-gray-500 mb-1">
              {msg.role === "user" ? "You" : "Assistant"}
            </strong>
            {msg.content}
          </div>
        ))}
      </div>

      {/* Input + submit */}
      <div className="flex gap-2">
        <Input
          value={question}
          onChange={(e) => setQuestion(e.target.value)}
          placeholder="Ask a question about the document"
          disabled={loading}
        />
        <Button onClick={handleAsk} disabled={loading || !question}>
          {loading ? "Thinking..." : "Ask"}
        </Button>
      </div>
    </div>
  );
}


// âœ… FILE: /convex/chats.ts

// Convex mutation and query for saving and retrieving chat history
import { mutation, query } from "convex/server";
import { v } from "convex/values";

export const saveChatMessage = mutation({
  args: {
    documentId: v.id("documents"),
    question: v.string(),
    answer: v.string(),
  },
  handler: async (ctx, args) => {
    await ctx.db.insert("chats", {
      documentId: args.documentId,
      question: args.question,
      answer: args.answer,
      createdAt: Date.now(),
    });
  },
});

export const getChatMessages = query({
  args: { documentId: v.id("documents") },
  handler: async (ctx, args) => {
    return await ctx.db
      .query("chats")
      .withIndex("by_document", (q) => q.eq("documentId", args.documentId))
      .order("asc")
      .collect();
  },
});


// âœ… FILE: /convex/schema.ts (bottom of file)

// Add chat table schema
// Fields: documentId, question, answer, createdAt
// Indexed by: documentId

table("chats", {
  documentId: id("documents"),
  question: string(),
  answer: string(),
  createdAt: number(),
}).index("by_document", ["documentId"]);


// âœ… FILE: /app/(main)/document/[id]/page.tsx

// Usage of chat component in document page
<ChatToDoc content={doc.content} documentId={doc._id} />